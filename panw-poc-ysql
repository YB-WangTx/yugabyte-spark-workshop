--POC cannon
ssh -i "kp-CANNON-aws.pem" centos@50.16.67.143

--Universe: alan-panw-audit-demo
sudo ssh -i /opt/yugabyte/yugaware/data/keys/3315aeea-aa87-43af-9c38-f72c20b9d8c0/yb-demo-aws-poc-selective_3315aeea-aa87-43af-9c38-f72c20b9d8c0-key.pem -ostricthostkeychecking=no -p 22 yugabyte@10.36.1.8

SSL_CERTFILE=~/yugabyte-client-tls-config/ca.crt ./master/bin/ycqlsh  10.36.1.8 9042  -u 'cassandra' --ssl
password: Panwaudit2023!

database: yugabyte
password: Panwaudit2023!
table: test

--app server
ssh -i "kp-CANNON-aws.pem" centos@44.214.44.45

--Create a keystore to access ssl enabled YCQL
scp -i "kp-CANNON-aws.pem" ~/Downloads/alan.crt centos@44.214.44.45:spark3yb/root.crt

--start Spark
cd /home/centos/spark-3.4.1-bin-hadoop3
./bin/spark-shell --conf spark.sql.extensions=com.datastax.spark.connector.CassandraSparkExtension --packages com.yugabyte.spark:spark-cassandra-connector_2.12:3.0-yb-8

import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.Row
import com.datastax.spark.connector._
import org.apache.spark.sql.cassandra.CassandraSQLRow
import org.apache.spark.sql.cassandra._
import com.datastax.spark.connector.cql.CassandraConnectorConf
import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window
import com.datastax.spark.connector.cql.CassandraConnector
import java.util.Properties


//val keyStore ="/home/centos/spark3yb/yb-keystore.jks"

//val jdbc_url = "jdbc:postgresql://10.36.2.198:5432/yugabyte"
//libraryDependencies += "org.postgresql" % "postgresql" % "your_postgresql_version"

object PostgresSSLConnection { 
   def main(args: Array[String]): Unit = { 
  // Create a SparkSession 
 val spark = SparkSession.builder() 
     .appName("PostgresSSLConnection") 
     .getOrCreate() 

// Configure PostgreSQL connection properties 
 val jdbcHostname = "10.36.2.198"
 val jdbcPort = "5432" 
 val jdbcDatabase = "yugabyte" 
 val table = "test"
 val jdbcUsername = "yugabyte" 
 val jdbcPassword = "Panwaudit2023" 

// Configure SSL properties 
  val sslMode = "require" 
// Use "require" for mandatory SSL 
  val sslRootCert = "path/to/root_cert.pem" 
  val sslClientCert = "path/to/client_cert.pem" 
  val sslClientKey = "path/to/client_key.pem" 
// Create the JDBC URL with SSL options 
  val jdbcUrl = s"jdbc:postgresql://$jdbcHostname:$jdbcPort/$jdbcDatabase?user=$jdbcUsername&password=$jdbcPassword&sslmode=$sslMode&sslrootcert=$sslRootCert&sslcert=$sslClientCert&sslkey=$sslClientKey" 
// Read data from the PostgreSQL database 
val df = spark.read .format("jdbc") .option("url", jdbcUrl) .option("dbtable", table) .load() 
// Perform operations on the DataFrame 
df.show() 
// Stop the SparkSession spark.stop() 

} }
