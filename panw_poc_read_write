cd /home/centos/spark-3.4.1-bin-hadoop3
./bin/spark-shell --conf spark.sql.extensions=com.datastax.spark.connector.CassandraSparkExtension --packages com.yugabyte.spark:spark-cassandra-connector_2.12:3.0-yb-8 --packages com.yugabyte:jdbc-yugabytedb:42.3.0

import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.Row
import com.datastax.spark.connector._
import org.apache.spark.sql.cassandra.CassandraSQLRow
import org.apache.spark.sql.cassandra._
import com.datastax.spark.connector.cql.CassandraConnectorConf
import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window
import com.datastax.spark.connector.cql.CassandraConnector
import java.util.Properties
import org.apache.spark.sql.SaveMode


--process data from YCQL
val host = "10.36.2.198"
val keyspace = "panw_test"
val table = "panw_audit_trail_demo"
val user = "cassandra"
val password = "Panwaudit2023!"
val keyStore ="/home/centos/spark3yb/yb-keystore.jks"

val conf = new SparkConf()
    .setAppName("yb.spark-jsonb")
    .setMaster("local[1]")
    .set("spark.cassandra.connection.localDC", "us-east-1")
    .set("spark.cassandra.connection.host", host)
    .set("spark.sql.catalog.ybcatalog", "com.datastax.spark.connector.datasource.CassandraCatalog")
    .set("spark.sql.extensions", "com.datastax.spark.connector.CassandraSparkExtensions")

//Spark session to YCQL

 val spark = SparkSession.builder()
             .config(conf)
             .config("spark.cassandra.connection.host", host)
             .config("spark.cassandra.connection.port", "9042")
             .config("spark.cassandra.connection.ssl.clientAuth.enabled", true)
             .config("spark.cassandra.auth.username", user)
             .config("spark.cassandra.auth.password", password)
             .config("spark.cassandra.connection.ssl.enabled", true)
             .config("spark.cassandra.connection.ssl.trustStore.type", "jks")
             .config("spark.cassandra.connection.ssl.trustStore.path", keyStore)
             .config("spark.cassandra.connection.ssl.trustStore.password", "ybcloud")
             .withExtensions(new CassandraSparkExtensions)
             .getOrCreate()

//Spark session
val spark = SparkSession.builder().config(conf).config("spark.cassandra.connection.host", host).config("spark.cassandra.connection.port", "9042").config("spark.cassandra.connection.ssl.clientAuth.enabled", true).config("spark.cassandra.auth.username", user).config("spark.cassandra.auth.password", password).config("spark.cassandra.connection.ssl.enabled", true).config("spark.cassandra.connection.ssl.trustStore.type", "jks").config("spark.cassandra.connection.ssl.trustStore.path", keyStore).config("spark.cassandra.connection.ssl.trustStore.password", "ybcloud").withExtensions(new CassandraSparkExtensions).getOrCreate()

